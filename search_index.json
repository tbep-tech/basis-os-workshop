[["index.html", "Course synopsis Agenda Instructors", " Course synopsis Welcome to the CERF 2021 open science workshop: core concepts for impactful research and resource management. Open science (OS) has been advocated as an effective approach to create reproducible, transparent, and actionable research products. However, widespread adoption among the coastal and estuarine research community has not occurred despite its perceived benefits. In the face of major challenges like global warming and sea level rise, the collaborative framework provided by OS is needed now more than ever. This workshop will cover a half-day of material introducing participants to core concepts of OS. The target audience includes anyone interested in applying OS in their own workflows as part of a larger research and resource management team. By the end of this workshop, you should have a solid understanding of fundamental concepts in open science and how they can be applied to help bridge the research-management divide. You will also have the skills to understand how collaborative open science tools can be used to increase efficiency and transparency, understand fundamental best practices for working with data to facilitate openness, and be able to apply these lessons within your own teams by effectively addressing barriers to adoption. Agenda 1: The basics of open science (30 min) 2: Open Science for collaboration (90 min) 3: Open science for impactful products (90 min) 4: Lowering barriers to inclusion and addressing key critiques (30 min) Instructors Dr. Chris Anastasiou is a Chief Water Quality Scientist and the Seagrass Mapping Program Lead for the Southwest Florida Water Management District. He holds a Ph.D. in Marine Science from the University of South Florida and has been working in and around the springs of Florida for more than 25 years. Dr. Marcus Beck is the Program Scientist for the Tampa Bay Estuary Program and is developing data analysis and visualization methods for Bay health indicators. He received his BS in Zoology from the University of Florida in 2007 and his MSc and PhD in Conservation Biology from the University of Minnesota in 2009 and 2013. Marcus has experience researching environmental indicators and developing open science products to support environmental decision-making. Marcus is also an avid software developer and creator of online dashboards that facilitate science communication.   This book is licensed under a Creative Commons Attribution 4.0 International License. This version of the book was built automatically with GitHub Actions on 2021-09-30. "],["basics.html", "1 Basics of open science 1.1 Lesson Outline 1.2 Goals and motivation 1.3 Why open science? 1.4 Learning and speaking the language of open science 1.5 The FAIR principles 1.6 Schools of thought", " 1 Basics of open science 1.1 Lesson Outline Goals and motivation Why open science? Learning and speaking the language of open science The FAIR principles Schools of thought 1.2 Goals and motivation This is the first module in our four hour workshop on open science. This module is designed to describe the need for open science, how it can improve research applications, and expose you to common ideas and terminology that we’ll be using throughout the day. Consider this your 30,000 foot view of open science. Our later modules will provide more detail on specific topics in open science that you can use for continued learning. Goal: get comfortable with key ideas and concepts for understanding open science Motivation: This is the first step in your open science journey! 1.3 Why open science? Let’s start with revisiting the scientific process. I’m sure this looks familiar to all of you. This is geared towards an applied research question. Our basic scientific approach to discovery is motivated by a question or research goal, developing a hypothesis for the question, collecting data based on the hypothesis, developing a tool that can be used for decision-making, and summarizing the results in a conventional format. In a little more detail, your workflow may look something like this. Many scientists, especially early career researchers (my past self included), may assume that this is sufficient to affect change. We write the report, send it out into the world, and move on to the next project. This is a common mentality: “This 500-page report will answer all of their questions!” From the other side, such as the manager or policy-maker, the report may be received like this: “This 500-page report answers none of my questions!” It’s dense, inaccessible, and there are probably questions about the underlying data and methods used to achieve the results. More importantly, it doesn’t present the information in an easily digestible format to quickly make the right decision. Sometimes, if you think you’re doing applied science, it may just be implied science that falls short of application. Why is this conventional approach to science ineffective at seeding change? As I’m sure we’re aware, the environmental management community is often siloed with each branch doing their own thing and speaking their own languages. Between the research (typically academic) and management community, we call this the research-management divide. A distinct barrier exists between how scientific products are developed and how they fail to meet management needs. This is often the result of communication barriers, irreproducible results, information loss with poor documentation, inaccessible data, and opaque workflows known only to the analyst. These barriers can occur at any stage of the research process. This compelling graphic from Michener et al. (1997) describes the atrophy of information in a closed approach to creating science. The last part is especially morbid. Sometimes, this is called the “bus factor”. What would happen to your important work and life achievements if you were hit by a bus? Would others be able to pick it up? Research products with a high bus factor are at risk of being lost if critical team members are no longer available. This is obviously a risk and real problem. So how do we make changes to our workflows to ensure we can achieve truly applied science using open tools and philosophies? 1.4 Learning and speaking the language of open science The tools and broader philosophy behind open science can help us bridge the research management divide. It involves a fundamental shift in how we approach the scientific process, both for your own internal workflows and how you can engage others in the process. By others, we mean not just researchers but specifically those that need the information to make informed decisions. Before we present a formal definition, let’s describe a modification of the conventional workflow that includes an open process to discovery and implementation (Beck et al. 2020; modified from Hampton et al. 2015). This workflow is similar to the original scientific method, but the technical components are open to managers and stakeholders, we’re treating data differently by using metadata and archiving, we’re creating summary documents that include source code with original, and we’re producing decision-support tools to meet the needs outside of the research community. More importantly, the process is iterative and not static. Throughout this workshop, we’ll learn about some open science tools that can be used in this generalized workflow to achieve better science in less time (Lowndes et al. 2017). Now let’s settle on a definition for open science (from Open Knowledge International, http://opendefinition.org/, https://creativecommons.org/): “The practice of science in such a way that others can collaborate and contribute, where research data, lab notes and other research processes are freely available, under terms that enable reuse, redistribution and reproduction of the research and its underlying data and methods.” Key words from this definition are highlighted in bold. There are very specific tools in the open science toolbox that speak to each of these key words. We’ll cover some of these later. From these key words, we can breakdown this definition into key principles. Open data Public availability of data Reusability and transparent workflows Data provenance and metadata Open process Iterative methods using reproducible workflows Collaboration with colleagues using web-based tools Leveraging external, open-source applications Open products Interactive web products for communication Dynamic documents with source code Integration with external networks for discoverability You’ll notice that web-based tools and open science are often discussed at the same time. Science existed before the internet and open science often focuses on how the two can leverage and support one another despite the latter being a relatively new addition to society. People often describe web-based tools as synonymous with open science. 1.5 The FAIR principles Advocates of open science also describe the use of the FAIR principles (Wilkinson et al. 2016) as a vehicle for achieving the former. It’s important to understand what they mean so that you can be fluent in both. The FAIR acronym is described as follows: Findable: The data have a globally unique and persistent identifier, including use of “rich” metadata. Accessible: Once found, the data can be retrieved using standardized communications protocols that are open, free, and universally implementable. Interoperable: The ability of data or tools from non-cooperating resources to integrate or work together with minimal effort. Reusable: If the above are achieved, the data and metadata are described in a way that they can be replicated and/or combined in different settings. Simply, what this means is: 1) each dataset has a name that doesn’t change and can be found with minimal effort using that name, 2) once it’s found, you can actually get your hands on it (e.g., not behind a paywall), 3) once you have it, you can use readily available tools to work with the data (e.g., not using proprietary software), and 4) you can actually apply the data for your own needs because it has sufficient context, including its reproduction, given the the first three principles are met. For our purposes, think of these ideas as general guidelines you can ask yourself when doing science. If you find that your work does not achieve FAIR status, then you’re probably not being as open as you could be. We’ll of course provide some tools to help you be FAIR and open. 1.6 Schools of thought Finally, it’s useful to make a distinction of how different people may talk about open science. This can help you better navigate conversations and become an advocate for open science in your own right. A useful paradigm is provided by Fecher and Friesike (2014) to describe open science as five distinct schools of thought: These are of course only conceptual boxes and there’s considerable overlap across all schools when open science is used in practice. For our purposes, we’ll be talking about ideas and tools from the pragmatic, infrastructure, and democratic schools of the thought. The end goal is to provide you with the means to create more efficient and impactful science that can more readily be used by others in a collaborative setting. References "],["collaborate.html", "2 Open Science for collaboration 2.1 Lesson Outline 2.2 Goals and motivation 2.3 Essential elements of collaboration 2.4 Tools for collaboration 2.5 Balancing and managing expectations", " 2 Open Science for collaboration 2.1 Lesson Outline Goals and motivation Essential elements of collaboration Tools for collaboration Balancing and managing expectations 2.2 Goals and motivation This is the second module in our four hour workshop on open science. This module will explore some open science tools to help you and your team become better collaborators and to better engage your science with external partners. We’ll introduce some essential elements of collaboration and discuss some readily available tools for doing so. We’ll close with a discussion on balancing and managing expectations for collaboration in the rapidly evolving online arena. Goal: understand methods of collaboration and the pros/cons of various tools Motivation: start building the tools for your open science toolbox 2.3 Essential elements of collaboration We start our deep dive into open science by focusing on collaboration as the single most important activity that can be enhanced through transparent, efficient, and reproducible tools. Having effective tools to work together is a critical theme of many open science practices. There are many tools in the toolbox and we need to introduce some core concepts before we demonstrate how to implement them in practice. 2.3.1 Workflow management How do you organize your work each day? How do you make sure pressing deadlines are met on schedule? How do you plan for short-term and long-term goals? Do you have a five-year, ten-year, or longer career plan? Work to achieve goals cannot be accomplished without a systematic approach to organizing tasks. Chances are, we each have our own system that works for us that was developed through trial and error. Although everyone has familiar workflows, they are often idiosyncratic and deeply entrenched by habit. That can be in direct conflict with collaboration when we try to mesh internal workflows with those of others. Does this look familiar? Although the above comic from xkcd speaks directly to file management, it hints at a broader problem of personal information management that can seriously complicate working with others. I’m sure we’ve all struggled to find that one file for that one project from a vague recollection of seeing it a few months ago. Collaborative work can be facilitated through workflow management that helps you break out of old habits. We’ll introduce some specific internet-based tools below to facilitate workflows either for yourself or, better yet, working with others. These can help propel you towards open science. Here, we introduce the Kanban approach to workflow management. The idea is simple. Create a task-oriented workflow of card management organized by progress. It looks something like this: As shown, this approach can work as a literal, physical board or as one used digitally through a web browser or other software. Every Kanban board has the following elements that allow you to work in a more informed manner: Provides a “big picture” of progress Organizes progress by discrete steps Establishes cards as specific tasks Many of the open science tools we describe below use this system. It is a generalizable format that works in different settings, whether it be general project management or something more formal like software development. 2.3.2 Version control A specific problem for workflow management that can be solved by open science tools is file management. Workflows can greatly be enhanced by tools that use strict guidelines for tracking changes and allowing a complete view of the evolution of a project. This is where version control comes in. I’m sure many of you have fallen into this trap: Version control is a way to track the development history of a project. It serves the joint purposes of: Formally documenting the changes that have been made to code or software Making sure that the development history is permanent Providing a system for collaborating across platforms (with friends!) It’s more than saving files. Documenting changes with a set of commands that follow strict rules provides a transparent record for yourself and others, and establishing permanency ensures that any of the changes that are made can be vetted and accessed as needed. Think of it as an insurance plan for your project. By far, the most widely use software for version control is Git. Although we do not cover the specifics of this software, it’s useful to understand the purpose and what it can do in making your work more open and impactful. Git is integrated with many popular open source development platforms, such as RStudio. Many people often confuse Git with GitHub. GitHub is an online platform for working collaboratively through Git AND it allows you to be open with your work. We’ll provide some examples below of how this can be done. Importantly, you do not need to be an expert in Git to be able to use GitHub. This speaks volumes for how team efficiency can be improved through better collaboration. Watch and learn Now we’ll demonstrate how to setup a version control project with RStudio, Git, and GitHub. 2.3.3 Data repositories How data are treated as living, dynamic pieces of information is critical to the whole ethos of open science. This is especially true when the FAIR principles are invoked. Data should not live on your hard drive as something only known to yourself. Although we will not cover data repositories in depth, it’s important to recognize the critical role that data archiving and metadata have in open science. How many times have you thought “wow, it would be great if I could have the data from this paper!” Making data open is a great way to propel science through better collaboration. The ease of getting a dataset online depends on where you want to put the data. In all cases, your dataset should be tidy and accompanied by metadata. For simple solutions, such as FTP hosting or putting a dataset on Google Drive, all you need to do is upload the data by hand. However, this doesn’t necessarily make it findable and the permanency is uncertain. The absolute best standard for hosting data online is through a Federated Data Repository: An online network of connected repositories that use similar standards to collectively store data for discovery and access. Uploading a dataset to one node of a repository will make it available through all other nodes. Such repositories follow strict, but necessary guidelines, to ensure your data live forever so long as the internet exists. The data are definitely findable (e.g., through a web search), accessible (free to download), and interoperable (accepted standards are ensured). The “reproducible” aspect can be debatable, but that can be solved through other means (e.g., code sharing). Some examples of data repositories, most are domain-specific: KNB: Knowledge Network for Biocomplexity, a general purpose repository for ecological data HydroShare: Data and models used in hydrology OPC: California Ocean Protection Council, marine and coastal datasets 2.3.4 Code of Conduct Every great collaborative team does not begin work before a Code of Conduct is created. This documents a set of community and social standards within which the work can be completed. It ensures all viewpoints are heard and respected and establishes a means by which conflicts can be resolved. Here’s a great example from our friends at openscapes. The goal of every code of conduct is to ensure an agreed upon set of norms are used by all team members to help create a safe and positive experience. Exercise Develop a code of conduct for your group in a shared workspace. Items to consider: How is inclusion defined and encouraged? How are similarities and differences recognized? How will conflicts be managed? 2.4 Tools for collaboration Now we introduce some specific web-based tools that you can use to improve collaboration and openness. We present them as a suite of options to consider based on the pros and cons associated with each tool. This is by no means a comprehensive list, but it should get you started towards better collaboration to leverage open science. 2.4.1 Slack https://slack.com/ What An online messaging platform for internal communication. Conversations can be organized by topic (via channels) or you can send direct messages to one or more team members. You can have multiple workspaces for different groups. Pros Alleviate email overload through quick, informal messaging. Offers a fresh approach to online communication. Cons Yet another thing to monitor. Free subscription limits archive of messages. Communication is limited to only those individuals in a workspace. 2.4.2 Trello https://trello.com/ What A Kanban style workflow organization platform. Can be used for personal organization or in teams. Card management allows you to assign due dates, add attachments, make checklists, assign tasks to yourself or team members, and label by themes. Pros Easy to use and can upgrade with “power-ups” for integration with other services (e.g., Google). Use across locations (e.g., from home or in the office) is easy because it’s based in a web browser. Cons Not entirely open because it’s only visible to yourself or those you explicitly invite. Free version is limited to only a handful of “power-ups”. 2.4.3 Google Drive https://google.com/drive What Cloud-based Platform for sharing documents, worksheets, slides, etc. Follows a familiar file-based GUI structure that is common to most operating systems. Pros Easy to use and can be a very open space for collaboration. Fairly interoperable with different file formats. Some functionality with version control (i.e., ability to “roll-back” to previous versions and to view changes). Cons Requires a Google account and access can be tricky depending on institution. Even though some versioning is provided, the format can encourage poor file management. Who knows what Google is doing with your data. 2.4.4 Office 365 https://google.com/drive What Cloud-based Platform for secure sharing of Microsoft documents, worksheets, slides, etc. Pros Easy to use and fully supports Microsoft products. Low barrier of inclusion to others that are already using Microsoft products (should be most folks). Cons Requires a Microsoft account and access can be tricky depending on institution. Maintains dependency on expensive Microsoft products that don’t facilitate reproducibility. Very often used in closed workflows. 2.4.5 GitHub https://github.com What Cloud-based Platform for sharing code with Git version control. Supports sharing of most file types, although code and text-based files are the primary use. Pros Collaborative and fully transparent work environment for files under version control. Supports workflow management through issue tracking and Kanban style project boards. Links to third-party platforms for archiving and DOI generation (e.g., Zenodo). Octocat mascot is super cute. Cons Learning curve is steep if you want to fully leverage version control. Not a formal data archival service by itself and file sizes are limited. Watch and learn Setting up a project management system with GitHub. Exercise In small groups, setup a shared workspace using GitHub and create a project management board. 2.5 Balancing and managing expectations Adopting new workflows and tools to facilitate collaboration are steps in the right direction for open science. Clearly, change from established norms and practices is not easy. It’s important to develop a realistic expectation of how this change may play out in the wild. First, realize that these changes are not going to happen overnight. Breaking free of entrenched workflows is like quitting bad habits. It’s not easy because they’re comfortable, familiar, and often habitual. Start small and work gradually towards adopting new ideas. Incremental progress is the name of the game. Getting others on board is another serious challenge. The sources of frustration you might have at the personal level apply to anyone else working in your team. Even more so, institutional roadblocks may exist. New software can raise red flags for IT support staff. It’s important to work with them to develop trust for the software and an accepted process for installation. Finally, the tools above are temporary. The single constant in open science is change. Use the tools with full realization that they may be appropriate for now, but something (hopefully) better will replace it in the future. "],["impact.html", "3 Open science for impactful products 3.1 Lesson Outline 3.2 Goals and motivation 3.3 Data as the foundation for open science 3.4 Principles of tidy data 3.5 Importance of metadata", " 3 Open science for impactful products 3.1 Lesson Outline Goals and motivation Data as the foundation for open science Principles of tidy data Importance of metadata 3.2 Goals and motivation This is the third module in our four hour workshop on open science. Now we focus on core principles for data management as the foundation for open science. We discuss the role of data management to support decisions using open science. Then, we introduce the concepts of tidy data as a unified format for storing information. We close with a discussion of metadata concepts and tools to make sure your data have a life beyond the project. Goal: understand best practices for data management as a key concept for open science Motivation: cultivate data as a living, shared resource 3.3 Data as the foundation for open science In the last module, we talked about collaboration as the single most important activity of open science. So, why are we now talking about data management? Understanding the tools of collaboration allows you to better engage with your colleagues and partners, but open engagement will mean nothing if your data look like garbage. Anybody who has ever worked with data knows that it comes in many shapes and sizes, most more like the right side of the above picture. Poor data management occurs for many reasons, but here’s a few of the common reasons: What’s easy to enter in the field doesn’t usually translate to easy analysis Egregious use of Excel as data management software Metadata is a chore that is often an afterthought It’s often said that 90% of working with data is cleaning (or “wrangling”), whereas the actual analysis and interpretation part is a small fraction of your total effort. Using better data management practices will not only help you save time, it’s also a service for your colleagues and future collaborators. Therefore, better data management leads to more open science. The FAIR principles outlined in the first module are especially useful when working with data for open science applications. Many of the collaborative tools in the second module can help you work towards putting FAIR data into practice. In this module, we’ll go a step further to discuss how data structure, including metadata, can produce a FAIR dataset. 3.4 Principles of tidy data At their core, tabular data allow you to store information as observations in rows and variables in columns, yet its very common to try to make a data table more than it should be. Unless you spend a lot of time working with data, it can be difficult to recognize common mistakes that lead to “table abuse”. Before we get into tidy data, we need to discuss some of the downfalls of Excel as a data management system. There are many examples that demonstrate how Excel has contributed to costly mistakes through the abuse of tables, often to the detriment of science (Ziemann, Eren, and El-Osta 2016). Excel allows you to abuse your data in many ways, such as adding color to cells, embedding formulas, and automatically formatting cell types. The problem occurs when this organization becomes ambiguous and only has meaning inside the head of the person who created the spreadsheet. Embedding formulas that reference specific locations in or across spreadsheets is also a nightmare scenario for reproducibility. If you absolutely must use Excel to store data, the only acceptable format is a rectangular, flat file. What do we mean by this? A rectangular file: Store data only in rows and columns in matrix format (e.g., 10 rows x 5 columns), with no “dangling” cells that have values outside of the grid or more than one table in a spreadsheet. A flat file: No cell formatting, no embedded formulas, no multiple spreadsheets in the same file, and data entered only as alphanumeric characters. Broman and Woo (2018) provide an excellent guide that expands on these ideas. Essentially, these best practices force you to isolate the analysis from the data - many people use Excel to mix the two, leading to problems. Now we can talk about tidy data. The “tidy” data principles developed by Hadley Wickham (Wickham 2014) are a set of simple rules for storing tabular data that have motivated the development of the wildly popular tidyverse suite of R packages (Wickham et al. 2019). The rules are simple: Each variable must have its own column; Each observation must have its own row; and, Each value must have its own cell. Graphically, these rules are shown below: Using these principles for data storage may seem unnatural at first because of a difference between what’s easy for entering data versus what makes sense for downstream analyses. For example, dates are often spread across multiple columns, such as having one column for each year of data where the header indicates the year that applies to data in each column. Using a tidy format also allows you to more easily join data between tables. This is a common task when you have information spread between different tables because: 1) it might not make sense to keep the data in the same table, and 2) the analysis depends on information from both tables. Tidy data shared between tables can be linked using a “key” as a common identifier. Watch and learn Making an untidy dataset tidy using Excel. Watch and learn Making an untidy dataset tidy using R. library(readxl) library(dplyr) library(tidyr) # import and wrangle dat &lt;- read_excel(&#39;data/untidy.xlsx&#39;, skip = 1) %&gt;% fill(Location) %&gt;% pivot_longer(cols = `2019`:`2021`, names_to = &#39;Year&#39;, values_to = &#39;acres/category&#39;) %&gt;% separate(col = `acres/category`, into = c(&#39;acres&#39;, &#39;category&#39;), sep = &#39;/&#39;) dat ## # A tibble: 27 × 5 ## Location Habitat Year acres category ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Clear Bay Seagrass 2019 519 B ## 2 Clear Bay Seagrass 2020 438 C ## 3 Clear Bay Seagrass 2021 375 A ## 4 Clear Bay Oysters 2019 390 B ## 5 Clear Bay Oysters 2020 875 B ## 6 Clear Bay Oysters 2021 724 A ## 7 Clear Bay Sand 2019 742 C ## 8 Clear Bay Sand 2020 702 A ## 9 Clear Bay Sand 2021 505 C ## 10 Fish Bay Seagrass 2019 930 B ## # … with 17 more rows 3.5 Importance of metadata How many times have you been sent a dataset without any idea what it contains or why it was created? How are you sure the information is valid and that your analysis takes into account the limitations of the data? How many times have you willfully sent someone a dataset without fully providing this information? Without metadata it’s impossible to know critical details about a dataset that can inform its analysis, and more importantly, its use to inform decision-making. Curating data should be synonymous with metadata generation and is an important part of open science. We cannot provide open data in good faith without also providing metadata. Metadata is literally defined as “data about data” or “information about information”. It varies from simple text descriptions of a dataset, such as “who”, “what”, “when”, “where”, “why”, and “how”, to more formalized standards with the intent of preparing your data for archival in a long-term repository. A useful definition is provided by Gilliland (2016): A suite of industry or disciplinary standards as well as additional internal and external documentation and other data necessary for the identification, representation, interoperability, technical management, performance, and use of data contained in an information system. Why don’t we see more metadata in the wild? Short answer is that it’s often an afterthought, if considered at all. Creating metadata is usually tedious and the return on investment is not apparent at onset of a project. However, the collective growth of sciences and its application to real world problems is dependent on metadata. The US Geological Survey provides a useful document on creating Metadata in “plain language” to distill the basic information contained in a metadata file. It provides a workflow for answering the “who”, “what”, “when”, “where”, “why”, and “how” questions for metadata. Below is a brief synopsis: What does the dataset describe? Information here would include very basic details about the dataset including a title, geographic extent, and period of time covered by the data. For geographic extent, this may often include explicit coordinates covering the study area. Location is useful for indexing your dataset relative to others, if for example, a researcher wanted to find data for all studies in the geographic extent of Tampa Bay. Who produced the dataset? This would be yourself and anyone else who has made a significant contribution to the development of a dataset. Data are increasingly being used as citable resources and including individuals that were important in its generation ensures proper attribution. If someone has spent hours toiling in the field to collect the data or hours visually scanning a spreadsheet for quality control, include them! Why was the dataset created? Describing why a dataset was created is critically important for understanding context. If others want to use your data, they need to know if it’s appropriate for their needs. Here you would describe the goal or objectives of the research for which the data were collected. It should be clear if there are limitations in your data defined by your goals. How was the dataset created? Here you would describe the methods used to generate the data, e.g., field sampling techniques, laboratory methods, etc. This information is important so others can know if you’ve used proper and accepted methods for generating the data. Citing existing SOPs or methods that are recognized standards in your field would be appropriate. How reliable are the data? It’s also important to explicitly note instances when the data could be questionable or inappropriate to use. Here you could describe any quality assurance or quality control (QAQC) checks that were used on the data. There are often formalized ways to do so, such as codes or descriptors in tabular data defining QAQC values (e.g., data in range, below detection limits, sensor out of service, etc.). How can someone get a copy of the dataset? Good metadata has information on who contact for getting the data. This contact may not be the same as who created the dataset (e.g., IT staff). For archived or publicly available data, this information is more important for who to contact should someone have questions. Information on obtaining a copy of the data should also describe any special software or licensing issues related to accessing the data. Once you’ve gathered this information, how do you turn it into literal metadata? It depends on how deep you want to go. At it’s simplest, your metadata could be a simple text file with answers to the questions. Or it could be a specific file format used by modern data archive repositories (e.g., EML format). Here’s an example of a bare bones metadata file. One could easily type this up in a text file or spreadsheet. 3.5.1 Data dictionaries Often the first step in documenting metadata is to create a data dictionary. Think of this as the specific description of the contents of a tabular data file. Developing a a data dictionary not only helps with metadata, but also helps you think more clearly about your data. Exercise Create a data dictionary for the tidy dataset from the previous example. References "],["implement.html", "4 Lowering barriers to inclusion and addressing key critiques", " 4 Lowering barriers to inclusion and addressing key critiques Learning curves/overhead associated with new the tools Fear of being open - exposure of mistakes, getting scooped, losing the competitive edge, etc. What is open to the public agency (operating in the sunshine)? What is open to the academic? Here’s some new text Awesome sauce Here’s a link "],["resources-for-continued-learning.html", "Resources for continued learning", " Resources for continued learning "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
