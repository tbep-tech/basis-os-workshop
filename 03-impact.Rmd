# Open science for impactful products {#impact}

```{r, echo = F, warning = F, message = F}
knitr::opts_chunk$set(echo = F, fig.align = 'center', out.width = '100%')

library(fontawesome)
```

## Lesson Outline

* [Goals and motivation]
* [Data as the foundation for open science]
* [Principles of tidy data]
* [Importance of metadata]

## Goals and motivation

This is the third module in our four hour workshop on open science. Now we focus on core principles for data management as the foundation for open science.  We discuss the role of data management to support decisions using open science.  Then, we introduce the concepts of tidy data as a unified format for storing information.  We close with a discussion of metadata concepts and tools to make sure your data have a life beyond the project.   

* __Goal__: understand best practices for data management as a key concept for open science
* __Motivation__: cultivate data as a living, shared resource

## Data as the foundation for open science

In the last module, we talked about collaboration as the single most important activity of open science. So, why are we now talking about data management?  Understanding the tools of collaboration allows you to better engage with your colleagues and partners, but open engagement will mean nothing if your data look like garbage.  

```{r}
knitr::include_graphics('img/datameme.jpg')
```

Anybody who has ever worked with data knows that it comes in many shapes and sizes, most more like the right side of the above picture.  Poor data management occurs for many reasons, but here's a few of the common reasons: 

* What's easy to enter in the field doesn't usually translate to easy analysis
* Egregious use of Excel as data management software
* Metadata is a chore that is often an afterthought

It's often said that 90% of working with data is cleaning (or "wrangling"), whereas the actual analysis and interpretation part is a small fraction of your total effort.  Using better data management practices will not only help you save time, it's also a service for your colleagues and future collaborators.  Therefore, better data management leads to more open science.  

The [FAIR](#fair) principles outlined in the first module are especially useful when working with data for open science applications.  Many of the collaborative tools in the second module can help you work towards putting FAIR data into practice.  In this module, we'll go a step further to discuss how data structure, including metadata, can produce a FAIR dataset. 

## Principles of tidy data

At their core, tabular data allow you to store information as observations in rows and variables in columns, yet its very common to try to make a data table more than it should be.  Unless you spend a lot of time working with data, it can be difficult to recognize common mistakes that lead to "table abuse".  

Before we get into tidy data, we need to discuss some of the downfalls of Excel as a data management system. There are [many examples](http://www.eusprig.org/horror-stories.htm) that demonstrate how Excel has contributed to costly mistakes through the abuse of tables, often to the detriment of science [@Ziemann16]. 

Excel allows you to abuse your data in many ways, such as adding color to cells, embedding formulas, and automatically formatting cell types.  The problem occurs when this organization becomes ambiguous and only has meaning inside the head of the person who created the spreadsheet.  Embedding formulas that reference specific locations in or across spreadsheets is also a nightmare scenario for reproducibility.

```{r, out.width = '80%'}
knitr::include_graphics('img/excel_bad.png')
```

If you absolutely must use Excel to store data, the only acceptable format is a rectangular, flat file. __Rectangular__ files store data only in rows and columns in matrix format (e.g., 10 rows x 5 columns), with no "dangling" cells that have values outside of the grid or more than one table in a spreadsheet. __Flat__ files have no cell formatting, no embedded formulas, no multiple spreadsheets in the same file, and data entered only as alphanumeric characters.

@Broman18 provide an excellent guide that expands on these ideas. Essentially, these best practices force you to isolate the analysis from the data - many people use Excel to mix the two, leading to problems. 

Now we can talk about tidy data. The "tidy" data principles developed by Hadley Wickham [@Wickham14c] are a set of simple rules for storing tabular data that have motivated the development of the wildly popular tidyverse suite of R packages [@Wickham19]. The rules are simple: 

1. Each variable must have its own column;
1. Each observation must have its own row; and,
1. Each value must have its own cell.

Graphically, these rules are shown below: 

```{r}
knitr::include_graphics('img/tidy-1.png')
```

Using these principles for data storage may seem unnatural at first because of a difference between what's easy for entering data versus what makes sense for downstream analyses.  For example, dates are often spread across multiple columns, such as having one column for each year of data where the header indicates the year that applies to data in each column.

Using a tidy format also allows you to more easily join data between tables.  This is a common task when you have information spread between different tables because: 1) it might not make sense to keep the data in the same table, and 2) the analysis depends on information from both tables. Tidy data shared between tables can be linked using a "key" as a common identifier.

```{r}
knitr::include_graphics('img/joins.png')
```

<h3>`r fa('chalkboard-teacher')` Watch and learn</h3>

Making an untidy dataset tidy using Excel. 

<h3>`r fa('chalkboard-teacher')` Watch and learn</h3>

Making an untidy dataset tidy using R.

## Importance of metadata

* What is metadata and why is it so important?

* What is a data dictionary

* Where do data live? 

* Exercise idea 1: Use your shared workspace to create a data dictionary for a sample dataset

* Exercise idea 2: Use your shared workspace to create a metadata file for a sample dataset

* Exercise idea 3: Make an untidy dataset tidy, this will have to be done with a simple dataset unless we want to get into other tools like the tidyverse